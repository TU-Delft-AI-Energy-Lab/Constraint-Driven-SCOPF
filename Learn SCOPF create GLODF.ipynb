{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76966592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The difference with DeepOPF or PINN is that our NN only has to predict the contingency flows and the cvxpylayer solves\n",
    "for all the rest i.e. constraints and optimization. That's why fewer training samples and a smaller NN compared to \n",
    "those papers is acceptable for this purpose. Those networks have to learn the whole DCOPF which is an optimization problem\n",
    "with multiple different constraints. What this NN actually has to learn is many simple linear constraints of the same type.\n",
    "\n",
    "This framework is thus clearly one where the outputs of a NN helps an optimization problem.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff78fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Aug 28 06:42:14 PM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: The specified module could not be found.')\n",
      "2.0\n",
      "9\n",
      "RAM Used (GB): 6.9992448\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import cvxpy_dcopf as cd\n",
    "import cvxpy_scopf as cs\n",
    "#import cvxpy_imb as ci\n",
    "import torch\n",
    "import torchvision\n",
    "import timeit\n",
    "import precontingency as pc\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from torch import Tensor\n",
    "import psutil\n",
    "\n",
    "\n",
    "data = pd.read_excel('IEEE118spyros.xlsx',sheet_name=None)\n",
    "Sbase = data['par']['base'][0]\n",
    "lcontingencies = range(len(data['line']))\n",
    "Nloads = len(data['load'])\n",
    "Ngens = len(data['gen'])\n",
    "Nlines = len(data['line'])\n",
    "Nbus = len(data['bus'])\n",
    "print(data[\"line\"]['max_f'][0]/Sbase)\n",
    "print(data['par']['refnode'][0])\n",
    "\n",
    "case = 'N-3'\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08a0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # GPU is available\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    # GPU is not available\n",
    "    device = torch.device('cpu')\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() >= 1:\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "else:\n",
    "    device_ids = None\n",
    "    \n",
    "num_workers = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f6b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "l = len(data['line'])\n",
    "\n",
    "if case == 'N-2':\n",
    "    N2 = np.array(list(itertools.combinations(range(l),2)))   \n",
    "\n",
    "elif case == 'N-3':\n",
    "    N3 = np.array(list(itertools.combinations(range(l),3)))\n",
    "    \n",
    "elif case == 'N-4':\n",
    "    N4 = np.array(list(itertools.combinations(range(l),4)))\n",
    "    \n",
    "elif case == 'N-5':\n",
    "    N5 = np.array(list(itertools.combinations(range(l),5)))\n",
    "    \n",
    "elif case == 'N-6':\n",
    "    N6 = np.array(list(itertools.combinations(range(l),6)))\n",
    "\n",
    "    \n",
    "def compute_lodf_N1(k):\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array(p[i,i]))\n",
    "    if PTDF_OO > 0.9999:\n",
    "        LODF_col = torch.zeros(size = (l,1)).to(device) # WRONG; should be just the values where PTDF = 1\n",
    "        singular = 1\n",
    "    else:\n",
    "        one = torch.eye(1)\n",
    "        RHS = (1/(one - PTDF_OO))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO,RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0 # if a line is outaged, there can be no flow over it. Set own LODF to zero\n",
    "        singular = 0\n",
    "\n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "\n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "    \n",
    "    return LODF_sheet_coo, singular\n",
    "    \n",
    "    \n",
    "def compute_lodf_N2(k):\n",
    "    i = N2[k,0]#N2[k][0]\n",
    "    j = N2[k,1]#N2[k][1]\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i],p[:,j]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array([[p[i,i],p[i,j]],[p[j,i],p[j,j]]]))\n",
    "    one = torch.eye(2).double()#.to(device)\n",
    "    subtract = (one - PTDF_OO).double()\n",
    "    if torch.linalg.det(subtract) > 1e-12:\n",
    "        RHS = (torch.linalg.solve(subtract, one))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO, RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0\n",
    "        LODF_col[j,:] = 0\n",
    "        singular = 0\n",
    "    else: \n",
    "        PTDF_OO[(PTDF_OO >= 0.9999) & (PTDF_OO < 1.00001)] = 1\n",
    "        LODF_col = torch.zeros(size = (l,2))#.to(device)\n",
    "        singular = 1\n",
    "        \n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "    LODF_sheet[j,:] = LODF_col[:,1].T\n",
    "    \n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "\n",
    "    return LODF_sheet_coo, singular\n",
    "\n",
    "def compute_lodf_N3(k):\n",
    "    i = N3[k,0]\n",
    "    j = N3[k,1]\n",
    "    r = N3[k,2]\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i],p[:,j],p[:,r]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array([[p[i,i],p[i,j],p[i,r]],[p[j,i],p[j,j],p[j,r]],[p[r,i],p[r,j],p[r,r]]]))\n",
    "    one = torch.eye(3)#.to(device)\n",
    "    subtract = one - PTDF_OO\n",
    "    if torch.linalg.det(subtract) > 1e-9: # 1e-12\n",
    "        RHS = (torch.linalg.solve(subtract, one))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO,RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0\n",
    "        LODF_col[j,:] = 0\n",
    "        LODF_col[r,:] = 0\n",
    "        singular = 0\n",
    "    else: \n",
    "        PTDF_OO[(PTDF_OO >= 0.9999) & (PTDF_OO < 1.0001)] = 1\n",
    "        LODF_col = torch.zeros(size = (l,3))#.to(device)\n",
    "        singular = 1\n",
    "\n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "    LODF_sheet[j,:] = LODF_col[:,1].T\n",
    "    LODF_sheet[r,:] = LODF_col[:,2].T\n",
    "\n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "\n",
    "    return LODF_sheet_coo, singular\n",
    "\n",
    "def compute_lodf_N4(k):\n",
    "    i = N4[k,0]\n",
    "    j = N4[k,1]\n",
    "    r = N4[k,2]\n",
    "    t = N4[k,3]\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i],p[:,j],p[:,r],p[:,t]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array([[p[i,i],p[i,j],p[i,r],p[i,t]],[p[j,i],p[j,j],p[j,r],p[j,t]],[p[r,i],p[r,j],p[r,r],p[r,t]],[p[t,i],p[t,j],p[t,r],p[t,t]]]))\n",
    "    one = torch.eye(4)#.to(device)\n",
    "    subtract = one - PTDF_OO\n",
    "    if torch.linalg.det(subtract) > 1e-9: # 1e-12\n",
    "        RHS = (torch.linalg.solve(subtract, one))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO,RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0\n",
    "        LODF_col[j,:] = 0\n",
    "        LODF_col[r,:] = 0\n",
    "        LODF_col[t,:] = 0\n",
    "        singular = 0\n",
    "    else: \n",
    "        PTDF_OO[(PTDF_OO >= 0.9999) & (PTDF_OO < 1.0001)] = 1\n",
    "        LODF_col = torch.zeros(size = (l,4))#.to(device)\n",
    "        singular = 1\n",
    "\n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "    LODF_sheet[j,:] = LODF_col[:,1].T\n",
    "    LODF_sheet[r,:] = LODF_col[:,2].T\n",
    "    LODF_sheet[t,:] = LODF_col[:,3].T\n",
    "\n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "\n",
    "    return LODF_sheet_coo, singular\n",
    "\n",
    "def compute_lodf_N5(k):\n",
    "    i = N5[k,0]\n",
    "    j = N5[k,1]\n",
    "    r = N5[k,2]\n",
    "    t = N5[k,3]\n",
    "    y = N5[k,4]\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i],p[:,j],p[:,r],p[:,t],p[:,y]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array([[p[i,i],p[i,j],p[i,r],p[i,t],p[i,y]],[p[j,i],p[j,j],p[j,r],p[j,t],p[j,y]],[p[r,i],p[r,j],p[r,r],p[r,t],p[r,y]],[p[t,i],p[t,j],p[t,r],p[t,t],p[t,y]],[p[y,i],p[y,j],p[y,r],p[y,t],p[y,y]]]))\n",
    "    one = torch.eye(5)#.to(device)\n",
    "    subtract = one - PTDF_OO\n",
    "    if torch.linalg.det(subtract) > 1e-9: # 1e-12\n",
    "        RHS = (torch.linalg.solve(subtract, one))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO,RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0\n",
    "        LODF_col[j,:] = 0\n",
    "        LODF_col[r,:] = 0\n",
    "        LODF_col[t,:] = 0\n",
    "        LODF_col[y,:] = 0\n",
    "        singular = 0\n",
    "    else: \n",
    "        PTDF_OO[(PTDF_OO >= 0.9999) & (PTDF_OO < 1.0001)] = 1\n",
    "        LODF_col = torch.zeros(size = (l,5))#.to(device)\n",
    "        singular = 1\n",
    "\n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "    LODF_sheet[j,:] = LODF_col[:,1].T\n",
    "    LODF_sheet[r,:] = LODF_col[:,2].T\n",
    "    LODF_sheet[t,:] = LODF_col[:,3].T\n",
    "    LODF_sheet[y,:] = LODF_col[:,4].T\n",
    "\n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "\n",
    "    return LODF_sheet_coo, singular\n",
    "\n",
    "def compute_lodf_N6(k):\n",
    "    i = N6[k,0]\n",
    "    j = N6[k,1]\n",
    "    r = N6[k,2]\n",
    "    t = N6[k,3]\n",
    "    y = N6[k,4]\n",
    "    w = N6[k,5]\n",
    "    LODF_sheet = torch.zeros((l,l))#.to(device)\n",
    "    PTDF_MO = np.transpose(np.array([p[:,i],p[:,j],p[:,r],p[:,t],p[:,y],p[:,w]]))\n",
    "    PTDF_MO = torch.from_numpy(PTDF_MO)\n",
    "    PTDF_OO = torch.from_numpy(np.array([[p[i,i],p[i,j],p[i,r],p[i,t],p[i,y],p[i,w]],[p[j,i],p[j,j],p[j,r],p[j,t],p[j,y],p[j,w]],[p[r,i],p[r,j],p[r,r],p[r,t],p[r,y],p[r,w]],[p[t,i],p[t,j],p[t,r],p[t,t],p[t,y],p[t,w]],[p[y,i],p[y,j],p[y,r],p[y,t],p[y,y],p[y,w]],[p[w,i],p[w,j],p[w,r],p[w,t],p[w,y],p[w,w]]]))\n",
    "    one = torch.eye(6)#.to(device)\n",
    "    subtract = one - PTDF_OO\n",
    "    if torch.linalg.det(subtract) > 1e-9: # 1e-12\n",
    "        RHS = (torch.linalg.solve(subtract, one))#.to(device)\n",
    "        LODF_col = torch.matmul(PTDF_MO,RHS)#.to(device)\n",
    "        LODF_col[i,:] = 0\n",
    "        LODF_col[j,:] = 0\n",
    "        LODF_col[r,:] = 0\n",
    "        LODF_col[t,:] = 0\n",
    "        LODF_col[y,:] = 0\n",
    "        LODF_col[w,:] = 0\n",
    "        singular = 0\n",
    "    else: \n",
    "        PTDF_OO[(PTDF_OO >= 0.9999) & (PTDF_OO < 1.0001)] = 1\n",
    "        LODF_col = torch.zeros(size = (l,6))#.to(device)\n",
    "        singular = 1\n",
    "\n",
    "    LODF_sheet[i,:] = LODF_col[:,0].T\n",
    "    LODF_sheet[j,:] = LODF_col[:,1].T\n",
    "    LODF_sheet[r,:] = LODF_col[:,2].T\n",
    "    LODF_sheet[t,:] = LODF_col[:,3].T\n",
    "    LODF_sheet[y,:] = LODF_col[:,4].T\n",
    "    LODF_sheet[w,:] = LODF_col[:,5].T\n",
    "\n",
    "    LODF_sheet[abs(LODF_sheet) < 1e-5] = 0\n",
    "    LODF_sheet_coo = LODF_sheet.to_sparse_coo()#.to(device)\n",
    "\n",
    "    return LODF_sheet_coo, singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/1055240 [00:00<?, ?it/s]C:\\Users\\bgiraud\\AppData\\Local\\Temp\\16\\ipykernel_18376\\2210812876.py:93: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  LODF_sheet[i,:] = LODF_col[:,0].T\n",
      "100%|███████████████████████████████████████████████████████████████████| 1055240/1055240 [09:14<00:00, 1904.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to build lodf matrix: 554.36589884758\n",
      "RAM Used (GB): 11.556409344\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    \n",
    "p = pc.compptdfs_alt(data)\n",
    "\n",
    "l = len(data['line'])\n",
    "start_lodf = time.time()\n",
    "\n",
    "if case == 'N-1':\n",
    "    Ncontingencies = l\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "        \n",
    "elif case == 'N-2':\n",
    "    Ncontingencies = int(l*(l-1)/2)\n",
    "    combinations = list(itertools.combinations(range(l), 2))\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "        \n",
    "elif case == 'N-3':\n",
    "    Ncontingencies = int(l*((l-1)/2)*((l-2)/3))\n",
    "    combinations = list(itertools.combinations(range(l), 3))\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "    \n",
    "elif case == 'N-4':\n",
    "    Ncontingencies = int(l*((l-1)/2)*((l-2)/3)*((l-3)/4))\n",
    "    combinations = list(itertools.combinations(range(l), 4))\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "    \n",
    "elif case == 'N-5':\n",
    "    Ncontingencies = int(l*((l-1)/2)*((l-2)/3)*((l-3)/4)*((l-4)/5))\n",
    "    combinations = list(itertools.combinations(range(l), 5))\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "    \n",
    "elif case == 'N-6':\n",
    "    Ncontingencies = int(l*((l-1)/2)*((l-2)/3)*((l-3)/4)*((l-4)/5)*((l-5)/6))\n",
    "    combinations = list(itertools.combinations(range(l), 6))\n",
    "    n_combinations = np.arange(Ncontingencies)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #==== initialize lodf \n",
    "    lodf_batch = 20000\n",
    "    tot_lodf_batches = math.ceil(Ncontingencies/lodf_batch)\n",
    "    LODF = []\n",
    "\n",
    "    #================ version 2\n",
    "    lodf_batch_num = 0\n",
    "    counter = 0\n",
    "    lodf_list = list(range(lodf_batch))\n",
    "    singular_list = []\n",
    "\n",
    "    for i in tqdm(range(Ncontingencies)):\n",
    "        if case == 'N-1':\n",
    "            result, singular = compute_lodf_N1(i)\n",
    "        elif case == 'N-2':\n",
    "            result, singular = compute_lodf_N2(i)\n",
    "        elif case == 'N-3':\n",
    "            result, singular = compute_lodf_N3(i)\n",
    "        elif case == 'N-4':\n",
    "            result, singular = compute_lodf_N4(i)\n",
    "        elif case == 'N-5':\n",
    "            result, singular = compute_lodf_N5(i)\n",
    "        elif case == 'N-6':\n",
    "            result, singular = compute_lodf_N6(i)\n",
    "        \n",
    "        # Append result directly to lodf_list and increment counter\n",
    "        lodf_list[counter] = result\n",
    "        counter += 1\n",
    "        if singular == 1:\n",
    "            singular_list.append(i)\n",
    "\n",
    "        if counter == lodf_batch:\n",
    "            # Concatenate lodf_list tensors in-place\n",
    "            lodf_concatenated = torch.cat(lodf_list, dim=1).to(torch.double).requires_grad_()\n",
    "            indices1 = lodf_concatenated._indices()[0].to(torch.float32)\n",
    "            indices2 = lodf_concatenated._indices()[1].to(torch.float32)\n",
    "            values = lodf_concatenated._values().to(torch.float32) \n",
    "\n",
    "            # Store lodf_concatenated in LODF_dict and reset counter and lodf_list\n",
    "            LODF.append((indices1, indices2, values))\n",
    "            counter = 0\n",
    "            lodf_list = list(range(lodf_batch))\n",
    "            lodf_batch_num += 1\n",
    "\n",
    "    if counter > 0:\n",
    "        lodf_list = lodf_list[:counter]\n",
    "        lodf_concatenated = torch.cat(lodf_list, dim=1).to(torch.double).requires_grad_()\n",
    "        indices1 = lodf_concatenated._indices()[0].to(torch.float32)\n",
    "        indices2 = lodf_concatenated._indices()[1].to(torch.float32)\n",
    "        values = lodf_concatenated._values().to(torch.float32) \n",
    "\n",
    "        LODF.append((indices1, indices2, values))\n",
    "\n",
    "    end_lodf = time.time()\n",
    "\n",
    "    time_lodf = end_lodf - start_lodf\n",
    "    print('time to build lodf matrix:', time_lodf)\n",
    "    \n",
    "\n",
    "\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(data['line'])\n",
    "index1 = LODF[0][0].detach()\n",
    "index2 = LODF[0][1].detach()\n",
    "indices = torch.stack((index1,index2)).detach()\n",
    "values = LODF[0][2].detach()\n",
    "shape = (l,int(l*lodf_batch))\n",
    "lodf = torch.sparse_coo_tensor(indices,values,size = shape).coalesce()\n",
    "\n",
    "values_coo = lodf.values()\n",
    "print('size value coo tensor:', values_coo.size())\n",
    "indices_coo = lodf.indices()\n",
    "print('size index tensor:', indices_coo.size())\n",
    "\n",
    "COO_elements = 0\n",
    "lodf_elements = l*l*Ncontingencies\n",
    "for b in range(len(LODF)):\n",
    "    COO_elements += torch.numel(values_coo) \n",
    "    COO_elements += torch.numel(indices_coo)\n",
    "\n",
    "\n",
    "print('total elements lodf:', lodf_elements)\n",
    "element_increase = (COO_elements/lodf_elements)*100 - 100\n",
    "print('element increase coo:', element_increase, '%')\n",
    "sparsity = (torch.numel(values_coo)/lodf_elements)*100 - 100\n",
    "print('sparsity:', sparsity, '%')\n",
    "\n",
    "print('compression:', lodf_elements/COO_elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307e82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ pickle\n",
    "import pickle\n",
    "\n",
    "# Specify the file path in Google Drive where the dictionary will be saved\n",
    "if case == 'N-1':\n",
    "    file_path_lodf = 'LODF_list/IEEE118/LODF_listN1_spyros.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE118/SL_N1.pkl'\n",
    "if case == 'N-2':\n",
    "    file_path_lodf = 'LODF_list/IEEE118/LODF_listN2_spyros.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE118/SL_N2.pkl'\n",
    "if case == 'N-3':\n",
    "    file_path_lodf = 'LODF_list/IEEE118/LODF_listN3spyros.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE118/SL_N3.pkl'\n",
    "if case == 'N-4':\n",
    "    file_path_lodf = 'LODF_list/IEEE118/LODF_listN4.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE118/SL_N4.pkl'\n",
    "if case == 'N-5':\n",
    "    file_path_lodf = 'LODF_list/IEEE27/LODF_listN5.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE27/SL_N5.pkl'\n",
    "if case == 'N-6':\n",
    "    file_path_lodf = 'LODF_list/IEEE27/LODF_listN6.pkl'\n",
    "    file_path_SL = 'LODF_list/IEEE27/SL_N6.pkl'\n",
    "\n",
    "# Save the dictionary to the specified file path using pickle\n",
    "with open(file_path_lodf, 'wb') as f:\n",
    "    pickle.dump(LODF, f)\n",
    "    \n",
    "with open(file_path_SL, 'wb') as f:\n",
    "    pickle.dump(singular_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nlines = 187\n",
    "k = 3\n",
    "\n",
    "sparsity_guarantee = (1-((k*(Nlines-k))/(Nlines**2)))*100\n",
    "print(sparsity_guarantee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c6c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2909c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5ac5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
